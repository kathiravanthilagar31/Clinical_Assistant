{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a918814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c45c914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    docs=SimpleDirectoryReader(filepath).load_data()\n",
    "    parser=SentenceSplitter(chunk_size=500,chunk_overlap=20)\n",
    "    chunks=parser.get_nodes_from_documents(docs)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2044556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\1 Kathir-Hope AI\\Projects\\GenAI\\Clinical_Assistant\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d403868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks=load_data('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1c70f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import StorageContext,Settings\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a99a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_store(chunks):\n",
    "    embed_model=OpenAIEmbedding(api_key=\"\")\n",
    "    Settings.embed_model=embed_model\n",
    "    \n",
    "    db=chromadb.PersistentClient(path=\"./db\")\n",
    "    chroma_collection=db.get_or_create_collection(\"clinical_data\")\n",
    "    \n",
    "    vectorstore=ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    \n",
    "    Storage=StorageContext.from_defaults(vector_store=vectorstore)\n",
    "    index=VectorStoreIndex.from_documents(documents=chunks,storage_context=Storage)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12afd757",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=vector_store(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db601f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_model=HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "# Settings.embed_model=embed_model\n",
    "# db=chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "# chroma_collection=db.get_or_create_collection(\"clinical_data\")\n",
    "# vector_store=ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "# Storage=StorageContext.from_defaults(vector_store=vector_store)\n",
    "# index=VectorStoreIndex.from_vector_store(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c956eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "import torch\n",
    "import torch.cuda\n",
    "\n",
    "llm_model=OpenAI(model_name=\"gpt-3.5-turbo\",api_key=\"\",\n",
    "                 temperature=0,\n",
    "                 system_prompt=\"You are a helpful and professional clinical assistant. Your sole purpose is to provide accurate answers to health and medical questions. Use ONLY the information provided in the given context. If the context does not contain the information needed to answer the question, politely state that you cannot answer based on the provided data.\"\n",
    ")\n",
    "Settings.llm=llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98539394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask a clinical question or type 'exit' to quit.\n",
      "Bot: Fever is a symptom that should prompt notification of a doctor when it develops during a flare-up of a condition like atopic dermatitis.\n",
      "Bot: I cannot answer that question based on the provided data.\n",
      "Bot: I cannot provide an answer to the query about \"LLM\" based on the provided data.\n",
      "Bot: ACE inhibitors are commonly used to treat high blood pressure. It is important for individuals with high blood pressure to continue seeing their physicians regularly, take their medication as prescribed, and follow any dietary or lifestyle recommendations provided by their healthcare professional. It is crucial not to stop taking the medication without consulting the prescribing physician. Additionally, individuals should be cautious about taking other medications alongside ACE inhibitors without first consulting their physician, as some medications may interact and affect blood pressure.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "print(\"Ask a clinical question or type 'exit' to quit.\")\n",
    "while True:\n",
    "    query = input(\"User: \")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "    \n",
    "    response = query_engine.query(query)\n",
    "    print(f\"Bot: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc0e22d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medicalasst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
